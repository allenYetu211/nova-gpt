{
    "sourceFile": "src/utils/MicrophoneRecord.tsx",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 19,
            "patches": [
                {
                    "date": 1681606598334,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1681606962884,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,10 +1,47 @@\n import Recorder from 'recorder-core'\n import 'recorder-core/src/engine/mp3'\n \n \n+class MicrophoneRecord {\n+  private rec;\n+  private success;\n+  constructor (success: () => void) {\n+    this.success = success\n+    this.rec = Recorder({ //本配置参数请参考下面的文档，有详细介绍\n+      type: \"mp3\", sampleRate: 16000, bitRate: 16 //mp3格式，指定采样率hz、比特率kbps，其他参数使用默认配置；注意：是数字的参数必须提供数字，不要用字符串；需要使用的type类型，需提前把格式支持文件加载进来，比如使用wav格式需要提前加载wav.js编码引擎\n+      , onProcess: function (buffers: any, powerLevel: any, bufferDuration: any, bufferSampleRate: any, newBufferIdx: any, asyncEnd: any) {\n+        //录音实时回调，大约1秒调用12次本回调，buffers为开始到现在的所有录音pcm数据块(16位小端LE)\n+        //可实时绘制波形（extensions目录内的waveview.js、wavesurfer.view.js、frequency.histogram.view.js插件功能）\n+        //可利用extensions/sonic.js插件实时变速变调，此插件计算量巨大，onProcess需要返回true开启异步模式\n+        //可实时上传（发送）数据，配合Recorder.SampleData方法，将buffers中的新数据连续的转换成pcm上传，或使用mock方法将新数据连续的转码成其他格式上传，可以参考文档里面的：Demo片段列表 -> 实时转码并上传-通用版；基于本功能可以做到：实时转发数据、实时保存数据、实时语音识别（ASR）等\n+      }\n+    });\n \n+    this.open()\n+  }\n \n+  init() {\n+\n+  }\n+  open() {\n+    this.rec.open(() => {//打开麦克风授权获得相关资源\n+      //dialog&&dialog.Cancel(); 如果开启了弹框，此处需要取消\n+      //rec.start() 此处可以立即开始录音，但不建议这样编写，因为open是一个延迟漫长的操作，通过两次用户操作来分别调用open和start是推荐的最佳流程\n+\n+      this.success && this.success();\n+    }, (msg: string, isUserNotAllow: any) => {//用户拒绝未授权或不支持\n+      //dialog&&dialog.Cancel(); 如果开启了弹框，此处需要取消\n+      console.log((isUserNotAllow ? \"UserNotAllow，\" : \"\") + \"无法录音:\" + msg);\n+    });\n+  }\n+\n+  recStart() {//打开了录音后才能进行start、stop调用\n+    this.rec.start();\n+  };\n+\n+}\n+\n var rec: any;\n /**调用open打开录音请求好录音权限**/\n export const MicrophoneRecord = function (success: () => any) {//一般在显示出录音按钮或相关的录音界面时进行此方法调用，后面用户点击开始录音时就能畅通无阻了\n   rec = Recorder({ //本配置参数请参考下面的文档，有详细介绍\n"
                },
                {
                    "date": 1681607094871,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,9 +1,9 @@\n import Recorder from 'recorder-core'\n import 'recorder-core/src/engine/mp3'\n \n \n-class MicrophoneRecord {\n+export class MicrophoneRecord {\n   private rec;\n   private success;\n   constructor (success: () => void) {\n     this.success = success\n@@ -34,66 +34,88 @@\n       console.log((isUserNotAllow ? \"UserNotAllow，\" : \"\") + \"无法录音:\" + msg);\n     });\n   }\n \n-  recStart() {//打开了录音后才能进行start、stop调用\n+  start() {//打开了录音后才能进行start、stop调用\n     this.rec.start();\n   };\n \n+  stop() {\n+    this.rec.stop((blob: Blob | MediaSource, duration: string) => {\n+      console.log(blob, (window.URL || webkitURL).createObjectURL(blob), \"时长:\" + duration + \"ms\");\n+      this.rec.close();//释放录音资源，当然可以不释放，后面可以连续调用start；但不释放时系统或浏览器会一直提示在录音，最佳操作是录完就close掉\n+      this.rec = null;\n+\n+      //已经拿到blob文件对象想干嘛就干嘛：立即播放、上传\n+\n+      /*** 【立即播放例子】 ***/\n+      const audio = document.createElement(\"audio\");\n+      audio.controls = true;\n+      document.body.appendChild(audio);\n+      //简单利用URL生成播放地址，注意不用了时需要revokeObjectURL，否则霸占内存\n+      audio.src = (window.URL || webkitURL).createObjectURL(blob);\n+      audio.play();\n+    }, (msg: string) => {\n+      console.log(\"录音失败:\" + msg);\n+      this.rec.close();//可以通过stop方法的第3个参数来自动调用close\n+      this.rec = null;\n+    });\n+  }\n+\n }\n \n-var rec: any;\n-/**调用open打开录音请求好录音权限**/\n-export const MicrophoneRecord = function (success: () => any) {//一般在显示出录音按钮或相关的录音界面时进行此方法调用，后面用户点击开始录音时就能畅通无阻了\n-  rec = Recorder({ //本配置参数请参考下面的文档，有详细介绍\n-    type: \"mp3\", sampleRate: 16000, bitRate: 16 //mp3格式，指定采样率hz、比特率kbps，其他参数使用默认配置；注意：是数字的参数必须提供数字，不要用字符串；需要使用的type类型，需提前把格式支持文件加载进来，比如使用wav格式需要提前加载wav.js编码引擎\n-    , onProcess: function (buffers: any, powerLevel: any, bufferDuration: any, bufferSampleRate: any, newBufferIdx: any, asyncEnd: any) {\n-      //录音实时回调，大约1秒调用12次本回调，buffers为开始到现在的所有录音pcm数据块(16位小端LE)\n-      //可实时绘制波形（extensions目录内的waveview.js、wavesurfer.view.js、frequency.histogram.view.js插件功能）\n-      //可利用extensions/sonic.js插件实时变速变调，此插件计算量巨大，onProcess需要返回true开启异步模式\n-      //可实时上传（发送）数据，配合Recorder.SampleData方法，将buffers中的新数据连续的转换成pcm上传，或使用mock方法将新数据连续的转码成其他格式上传，可以参考文档里面的：Demo片段列表 -> 实时转码并上传-通用版；基于本功能可以做到：实时转发数据、实时保存数据、实时语音识别（ASR）等\n-    }\n-  });\n+// var rec: any;\n+// /**调用open打开录音请求好录音权限**/\n+// export const MicrophoneRecord = function (success: () => any) {//一般在显示出录音按钮或相关的录音界面时进行此方法调用，后面用户点击开始录音时就能畅通无阻了\n+//   rec = Recorder({ //本配置参数请参考下面的文档，有详细介绍\n+//     type: \"mp3\", sampleRate: 16000, bitRate: 16 //mp3格式，指定采样率hz、比特率kbps，其他参数使用默认配置；注意：是数字的参数必须提供数字，不要用字符串；需要使用的type类型，需提前把格式支持文件加载进来，比如使用wav格式需要提前加载wav.js编码引擎\n+//     , onProcess: function (buffers: any, powerLevel: any, bufferDuration: any, bufferSampleRate: any, newBufferIdx: any, asyncEnd: any) {\n+//       //录音实时回调，大约1秒调用12次本回调，buffers为开始到现在的所有录音pcm数据块(16位小端LE)\n+//       //可实时绘制波形（extensions目录内的waveview.js、wavesurfer.view.js、frequency.histogram.view.js插件功能）\n+//       //可利用extensions/sonic.js插件实时变速变调，此插件计算量巨大，onProcess需要返回true开启异步模式\n+//       //可实时上传（发送）数据，配合Recorder.SampleData方法，将buffers中的新数据连续的转换成pcm上传，或使用mock方法将新数据连续的转码成其他格式上传，可以参考文档里面的：Demo片段列表 -> 实时转码并上传-通用版；基于本功能可以做到：实时转发数据、实时保存数据、实时语音识别（ASR）等\n+//     }\n+//   });\n \n-  //var dialog=createDelayDialog(); 我们可以选择性的弹一个对话框：为了防止移动端浏览器存在第三种情况：用户忽略，并且（或者国产系统UC系）浏览器没有任何回调，此处demo省略了弹窗的代码\n-  rec.open(function () {//打开麦克风授权获得相关资源\n-    //dialog&&dialog.Cancel(); 如果开启了弹框，此处需要取消\n-    //rec.start() 此处可以立即开始录音，但不建议这样编写，因为open是一个延迟漫长的操作，通过两次用户操作来分别调用open和start是推荐的最佳流程\n+//   //var dialog=createDelayDialog(); 我们可以选择性的弹一个对话框：为了防止移动端浏览器存在第三种情况：用户忽略，并且（或者国产系统UC系）浏览器没有任何回调，此处demo省略了弹窗的代码\n+//   rec.open(function () {//打开麦克风授权获得相关资源\n+//     //dialog&&dialog.Cancel(); 如果开启了弹框，此处需要取消\n+//     //rec.start() 此处可以立即开始录音，但不建议这样编写，因为open是一个延迟漫长的操作，通过两次用户操作来分别调用open和start是推荐的最佳流程\n \n-    success && success();\n-  }, function (msg: string, isUserNotAllow: any) {//用户拒绝未授权或不支持\n-    //dialog&&dialog.Cancel(); 如果开启了弹框，此处需要取消\n-    console.log((isUserNotAllow ? \"UserNotAllow，\" : \"\") + \"无法录音:\" + msg);\n-  });\n-};\n+//     success && success();\n+//   }, function (msg: string, isUserNotAllow: any) {//用户拒绝未授权或不支持\n+//     //dialog&&dialog.Cancel(); 如果开启了弹框，此处需要取消\n+//     console.log((isUserNotAllow ? \"UserNotAllow，\" : \"\") + \"无法录音:\" + msg);\n+//   });\n+// };\n \n-/**开始录音**/\n-function recStart() {//打开了录音后才能进行start、stop调用\n-  rec.start();\n-};\n+// /**开始录音**/\n+// function recStart() {//打开了录音后才能进行start、stop调用\n+//   rec.start();\n+// };\n \n-/**结束录音**/\n-function recStop() {\n-  rec.stop(function (blob: Blob | MediaSource, duration: string) {\n-    console.log(blob, (window.URL || webkitURL).createObjectURL(blob), \"时长:\" + duration + \"ms\");\n-    rec.close();//释放录音资源，当然可以不释放，后面可以连续调用start；但不释放时系统或浏览器会一直提示在录音，最佳操作是录完就close掉\n-    rec = null;\n+// /**结束录音**/\n+// function recStop() {\n+//   rec.stop(function (blob: Blob | MediaSource, duration: string) {\n+//     console.log(blob, (window.URL || webkitURL).createObjectURL(blob), \"时长:\" + duration + \"ms\");\n+//     rec.close();//释放录音资源，当然可以不释放，后面可以连续调用start；但不释放时系统或浏览器会一直提示在录音，最佳操作是录完就close掉\n+//     rec = null;\n \n-    //已经拿到blob文件对象想干嘛就干嘛：立即播放、上传\n+//     //已经拿到blob文件对象想干嘛就干嘛：立即播放、上传\n \n-    /*** 【立即播放例子】 ***/\n-    var audio = document.createElement(\"audio\");\n-    audio.controls = true;\n-    document.body.appendChild(audio);\n-    //简单利用URL生成播放地址，注意不用了时需要revokeObjectURL，否则霸占内存\n-    audio.src = (window.URL || webkitURL).createObjectURL(blob);\n-    audio.play();\n-  }, function (msg: string) {\n-    console.log(\"录音失败:\" + msg);\n-    rec.close();//可以通过stop方法的第3个参数来自动调用close\n-    rec = null;\n-  });\n-};\n+//     /*** 【立即播放例子】 ***/\n+//     var audio = document.createElement(\"audio\");\n+//     audio.controls = true;\n+//     document.body.appendChild(audio);\n+//     //简单利用URL生成播放地址，注意不用了时需要revokeObjectURL，否则霸占内存\n+//     audio.src = (window.URL || webkitURL).createObjectURL(blob);\n+//     audio.play();\n+//   }, function (msg: string) {\n+//     console.log(\"录音失败:\" + msg);\n+//     rec.close();//可以通过stop方法的第3个参数来自动调用close\n+//     rec = null;\n+//   });\n+// };\n \n \n //我们可以选择性的弹一个对话框：为了防止移动端浏览器存在第三种情况：用户忽略，并且（或者国产系统UC系）浏览器没有任何回调\n /*伪代码：\n"
                },
                {
                    "date": 1681607106867,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -15,15 +15,11 @@\n         //可利用extensions/sonic.js插件实时变速变调，此插件计算量巨大，onProcess需要返回true开启异步模式\n         //可实时上传（发送）数据，配合Recorder.SampleData方法，将buffers中的新数据连续的转换成pcm上传，或使用mock方法将新数据连续的转码成其他格式上传，可以参考文档里面的：Demo片段列表 -> 实时转码并上传-通用版；基于本功能可以做到：实时转发数据、实时保存数据、实时语音识别（ASR）等\n       }\n     });\n-\n     this.open()\n   }\n \n-  init() {\n-\n-  }\n   open() {\n     this.rec.open(() => {//打开麦克风授权获得相关资源\n       //dialog&&dialog.Cancel(); 如果开启了弹框，此处需要取消\n       //rec.start() 此处可以立即开始录音，但不建议这样编写，因为open是一个延迟漫长的操作，通过两次用户操作来分别调用open和start是推荐的最佳流程\n"
                },
                {
                    "date": 1681607115755,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -19,8 +19,9 @@\n     this.open()\n   }\n \n   open() {\n+    console.log('open', open)\n     this.rec.open(() => {//打开麦克风授权获得相关资源\n       //dialog&&dialog.Cancel(); 如果开启了弹框，此处需要取消\n       //rec.start() 此处可以立即开始录音，但不建议这样编写，因为open是一个延迟漫长的操作，通过两次用户操作来分别调用open和start是推荐的最佳流程\n \n"
                },
                {
                    "date": 1681607782463,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,139 +1,61 @@\n-import Recorder from 'recorder-core'\n-import 'recorder-core/src/engine/mp3'\n+export const MicrophoneRecord = () =>\n+  new Promise(async resolve => {\n+    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n+    const mediaRecorder = new MediaRecorder(stream);\n+    const audioChunks: BlobPart[] = [];\n \n-\n-export class MicrophoneRecord {\n-  private rec;\n-  private success;\n-  constructor (success: () => void) {\n-    this.success = success\n-    this.rec = Recorder({ //本配置参数请参考下面的文档，有详细介绍\n-      type: \"mp3\", sampleRate: 16000, bitRate: 16 //mp3格式，指定采样率hz、比特率kbps，其他参数使用默认配置；注意：是数字的参数必须提供数字，不要用字符串；需要使用的type类型，需提前把格式支持文件加载进来，比如使用wav格式需要提前加载wav.js编码引擎\n-      , onProcess: function (buffers: any, powerLevel: any, bufferDuration: any, bufferSampleRate: any, newBufferIdx: any, asyncEnd: any) {\n-        //录音实时回调，大约1秒调用12次本回调，buffers为开始到现在的所有录音pcm数据块(16位小端LE)\n-        //可实时绘制波形（extensions目录内的waveview.js、wavesurfer.view.js、frequency.histogram.view.js插件功能）\n-        //可利用extensions/sonic.js插件实时变速变调，此插件计算量巨大，onProcess需要返回true开启异步模式\n-        //可实时上传（发送）数据，配合Recorder.SampleData方法，将buffers中的新数据连续的转换成pcm上传，或使用mock方法将新数据连续的转码成其他格式上传，可以参考文档里面的：Demo片段列表 -> 实时转码并上传-通用版；基于本功能可以做到：实时转发数据、实时保存数据、实时语音识别（ASR）等\n-      }\n+    mediaRecorder.addEventListener(\"dataavailable\", event => {\n+      audioChunks.push(event.data);\n     });\n-    this.open()\n-  }\n \n-  open() {\n-    console.log('open', open)\n-    this.rec.open(() => {//打开麦克风授权获得相关资源\n-      //dialog&&dialog.Cancel(); 如果开启了弹框，此处需要取消\n-      //rec.start() 此处可以立即开始录音，但不建议这样编写，因为open是一个延迟漫长的操作，通过两次用户操作来分别调用open和start是推荐的最佳流程\n+    const start = () => mediaRecorder.start();\n \n-      this.success && this.success();\n-    }, (msg: string, isUserNotAllow: any) => {//用户拒绝未授权或不支持\n-      //dialog&&dialog.Cancel(); 如果开启了弹框，此处需要取消\n-      console.log((isUserNotAllow ? \"UserNotAllow，\" : \"\") + \"无法录音:\" + msg);\n+    const stop = () =>\n+      new Promise(resolve => {\n+        mediaRecorder.addEventListener(\"stop\", () => {\n+          const audioBlob = new Blob(audioChunks);\n+          const audioUrl = URL.createObjectURL(audioBlob);\n+          const audio = new Audio(audioUrl);\n+          const play = () => audio.play();\n+          resolve({ audioBlob, audioUrl, play });\n+        });\n+\n+        mediaRecorder.stop();\n+      });\n+\n+    resolve({ start, stop });\n+  });\n+\n+class MicrophoneRecord {\n+  private stream: MediaStream | null = null;\n+  private mediaRecorder: MediaRecorder | null = null;\n+  private audioChunks: BlobPart[] = [];\n+\n+  async init() {\n+    this.stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n+    this.mediaRecorder = new MediaRecorder(this.stream);\n+\n+    this.mediaRecorder.addEventListener(\"dataavailable\", event => {\n+      this.audioChunks.push(event.data);\n     });\n   }\n \n-  start() {//打开了录音后才能进行start、stop调用\n-    this.rec.start();\n-  };\n+  start() {\n+    this.mediaRecorder!.start();\n+  }\n \n   stop() {\n-    this.rec.stop((blob: Blob | MediaSource, duration: string) => {\n-      console.log(blob, (window.URL || webkitURL).createObjectURL(blob), \"时长:\" + duration + \"ms\");\n-      this.rec.close();//释放录音资源，当然可以不释放，后面可以连续调用start；但不释放时系统或浏览器会一直提示在录音，最佳操作是录完就close掉\n-      this.rec = null;\n+    new Promise(resolve => {\n+      this.mediaRecorder!.addEventListener(\"stop\", () => {\n+        const audioBlob = new Blob(this.audioChunks);\n+        const audioUrl = URL.createObjectURL(audioBlob);\n+        const audio = new Audio(audioUrl);\n+        const play = () => audio.play();\n+        resolve({ audioBlob, audioUrl, play });\n+      });\n \n-      //已经拿到blob文件对象想干嘛就干嘛：立即播放、上传\n-\n-      /*** 【立即播放例子】 ***/\n-      const audio = document.createElement(\"audio\");\n-      audio.controls = true;\n-      document.body.appendChild(audio);\n-      //简单利用URL生成播放地址，注意不用了时需要revokeObjectURL，否则霸占内存\n-      audio.src = (window.URL || webkitURL).createObjectURL(blob);\n-      audio.play();\n-    }, (msg: string) => {\n-      console.log(\"录音失败:\" + msg);\n-      this.rec.close();//可以通过stop方法的第3个参数来自动调用close\n-      this.rec = null;\n+      this.mediaRecorder!.stop();\n     });\n   }\n \n }\n-\n-// var rec: any;\n-// /**调用open打开录音请求好录音权限**/\n-// export const MicrophoneRecord = function (success: () => any) {//一般在显示出录音按钮或相关的录音界面时进行此方法调用，后面用户点击开始录音时就能畅通无阻了\n-//   rec = Recorder({ //本配置参数请参考下面的文档，有详细介绍\n-//     type: \"mp3\", sampleRate: 16000, bitRate: 16 //mp3格式，指定采样率hz、比特率kbps，其他参数使用默认配置；注意：是数字的参数必须提供数字，不要用字符串；需要使用的type类型，需提前把格式支持文件加载进来，比如使用wav格式需要提前加载wav.js编码引擎\n-//     , onProcess: function (buffers: any, powerLevel: any, bufferDuration: any, bufferSampleRate: any, newBufferIdx: any, asyncEnd: any) {\n-//       //录音实时回调，大约1秒调用12次本回调，buffers为开始到现在的所有录音pcm数据块(16位小端LE)\n-//       //可实时绘制波形（extensions目录内的waveview.js、wavesurfer.view.js、frequency.histogram.view.js插件功能）\n-//       //可利用extensions/sonic.js插件实时变速变调，此插件计算量巨大，onProcess需要返回true开启异步模式\n-//       //可实时上传（发送）数据，配合Recorder.SampleData方法，将buffers中的新数据连续的转换成pcm上传，或使用mock方法将新数据连续的转码成其他格式上传，可以参考文档里面的：Demo片段列表 -> 实时转码并上传-通用版；基于本功能可以做到：实时转发数据、实时保存数据、实时语音识别（ASR）等\n-//     }\n-//   });\n-\n-//   //var dialog=createDelayDialog(); 我们可以选择性的弹一个对话框：为了防止移动端浏览器存在第三种情况：用户忽略，并且（或者国产系统UC系）浏览器没有任何回调，此处demo省略了弹窗的代码\n-//   rec.open(function () {//打开麦克风授权获得相关资源\n-//     //dialog&&dialog.Cancel(); 如果开启了弹框，此处需要取消\n-//     //rec.start() 此处可以立即开始录音，但不建议这样编写，因为open是一个延迟漫长的操作，通过两次用户操作来分别调用open和start是推荐的最佳流程\n-\n-//     success && success();\n-//   }, function (msg: string, isUserNotAllow: any) {//用户拒绝未授权或不支持\n-//     //dialog&&dialog.Cancel(); 如果开启了弹框，此处需要取消\n-//     console.log((isUserNotAllow ? \"UserNotAllow，\" : \"\") + \"无法录音:\" + msg);\n-//   });\n-// };\n-\n-// /**开始录音**/\n-// function recStart() {//打开了录音后才能进行start、stop调用\n-//   rec.start();\n-// };\n-\n\\ No newline at end of file\n-// /**结束录音**/\n-// function recStop() {\n-//   rec.stop(function (blob: Blob | MediaSource, duration: string) {\n-//     console.log(blob, (window.URL || webkitURL).createObjectURL(blob), \"时长:\" + duration + \"ms\");\n-//     rec.close();//释放录音资源，当然可以不释放，后面可以连续调用start；但不释放时系统或浏览器会一直提示在录音，最佳操作是录完就close掉\n-//     rec = null;\n-\n-//     //已经拿到blob文件对象想干嘛就干嘛：立即播放、上传\n-\n-//     /*** 【立即播放例子】 ***/\n-//     var audio = document.createElement(\"audio\");\n-//     audio.controls = true;\n-//     document.body.appendChild(audio);\n-//     //简单利用URL生成播放地址，注意不用了时需要revokeObjectURL，否则霸占内存\n-//     audio.src = (window.URL || webkitURL).createObjectURL(blob);\n-//     audio.play();\n-//   }, function (msg: string) {\n-//     console.log(\"录音失败:\" + msg);\n-//     rec.close();//可以通过stop方法的第3个参数来自动调用close\n-//     rec = null;\n-//   });\n-// };\n-\n-\n-//我们可以选择性的弹一个对话框：为了防止移动端浏览器存在第三种情况：用户忽略，并且（或者国产系统UC系）浏览器没有任何回调\n-/*伪代码：\n-function createDelayDialog(){\n-    if(Is Mobile){//只针对移动端\n-        return new Alert Dialog Component\n-            .Message(\"录音功能需要麦克风权限，请允许；如果未看到任何请求，请点击忽略~\")\n-            .Button(\"忽略\")\n-            .OnClick(function(){//明确是用户点击的按钮，此时代表浏览器没有发起任何权限请求\n-                //此处执行fail逻辑\n-                console.log(\"无法录音：权限请求被忽略\");\n-            })\n-            .OnCancel(NOOP)//自动取消的对话框不需要任何处理\n-            .Delay(8000); //延迟8秒显示，这么久还没有操作基本可以判定浏览器有毛病\n-    };\n-};\n-*/\n-\n-\n-//这里假设立即运行，只录3秒，录完后立即播放，本段代码copy到控制台内可直接运行\n-// recOpen(function () {\n-//   recStart();\n-//   setTimeout(recStop, 3000);\n-// });\n"
                },
                {
                    "date": 1681607809743,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,32 +1,4 @@\n-export const MicrophoneRecord = () =>\n-  new Promise(async resolve => {\n-    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n-    const mediaRecorder = new MediaRecorder(stream);\n-    const audioChunks: BlobPart[] = [];\n-\n-    mediaRecorder.addEventListener(\"dataavailable\", event => {\n-      audioChunks.push(event.data);\n-    });\n-\n-    const start = () => mediaRecorder.start();\n-\n-    const stop = () =>\n-      new Promise(resolve => {\n-        mediaRecorder.addEventListener(\"stop\", () => {\n-          const audioBlob = new Blob(audioChunks);\n-          const audioUrl = URL.createObjectURL(audioBlob);\n-          const audio = new Audio(audioUrl);\n-          const play = () => audio.play();\n-          resolve({ audioBlob, audioUrl, play });\n-        });\n-\n-        mediaRecorder.stop();\n-      });\n-\n-    resolve({ start, stop });\n-  });\n-\n class MicrophoneRecord {\n   private stream: MediaStream | null = null;\n   private mediaRecorder: MediaRecorder | null = null;\n   private audioChunks: BlobPart[] = [];\n@@ -40,22 +12,22 @@\n     });\n   }\n \n   start() {\n-    this.mediaRecorder!.start();\n+    this.mediaRecorder && this.mediaRecorder.start();\n   }\n \n   stop() {\n     new Promise(resolve => {\n-      this.mediaRecorder!.addEventListener(\"stop\", () => {\n+      this.mediaRecorder && this.mediaRecorder.addEventListener(\"stop\", () => {\n         const audioBlob = new Blob(this.audioChunks);\n         const audioUrl = URL.createObjectURL(audioBlob);\n         const audio = new Audio(audioUrl);\n         const play = () => audio.play();\n         resolve({ audioBlob, audioUrl, play });\n       });\n \n-      this.mediaRecorder!.stop();\n+      this.mediaRecorder && this.mediaRecorder.stop();\n     });\n   }\n \n }\n"
                },
                {
                    "date": 1681607840338,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,9 +1,13 @@\n-class MicrophoneRecord {\n+export class MicrophoneRecord {\n   private stream: MediaStream | null = null;\n   private mediaRecorder: MediaRecorder | null = null;\n   private audioChunks: BlobPart[] = [];\n \n+  constructor() {\n+    this.init();\n+  }\n+\n   async init() {\n     this.stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n     this.mediaRecorder = new MediaRecorder(this.stream);\n \n"
                },
                {
                    "date": 1681608228931,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,10 +1,11 @@\n export class MicrophoneRecord {\n   private stream: MediaStream | null = null;\n   private mediaRecorder: MediaRecorder | null = null;\n   private audioChunks: BlobPart[] = [];\n+  private audio: HTMLAudioElement | null = null;\n \n-  constructor() {\n+  constructor () {\n     this.init();\n   }\n \n   async init() {\n@@ -24,14 +25,17 @@\n     new Promise(resolve => {\n       this.mediaRecorder && this.mediaRecorder.addEventListener(\"stop\", () => {\n         const audioBlob = new Blob(this.audioChunks);\n         const audioUrl = URL.createObjectURL(audioBlob);\n-        const audio = new Audio(audioUrl);\n-        const play = () => audio.play();\n-        resolve({ audioBlob, audioUrl, play });\n+        this.audio = new Audio(audioUrl);\n+        resolve({ audioBlob, audioUrl });\n       });\n \n       this.mediaRecorder && this.mediaRecorder.stop();\n     });\n   }\n \n+  play() {\n+    this.audio && this.audio.play();\n+  }\n+\n }\n"
                },
                {
                    "date": 1681608236789,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -26,8 +26,9 @@\n       this.mediaRecorder && this.mediaRecorder.addEventListener(\"stop\", () => {\n         const audioBlob = new Blob(this.audioChunks);\n         const audioUrl = URL.createObjectURL(audioBlob);\n         this.audio = new Audio(audioUrl);\n+        this.play()\n         resolve({ audioBlob, audioUrl });\n       });\n \n       this.mediaRecorder && this.mediaRecorder.stop();\n"
                },
                {
                    "date": 1681608265250,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -21,8 +21,10 @@\n     this.mediaRecorder && this.mediaRecorder.start();\n   }\n \n   stop() {\n+    this.mediaRecorder && this.mediaRecorder.stop();\n+\n     new Promise(resolve => {\n       this.mediaRecorder && this.mediaRecorder.addEventListener(\"stop\", () => {\n         const audioBlob = new Blob(this.audioChunks);\n         const audioUrl = URL.createObjectURL(audioBlob);\n@@ -30,10 +32,10 @@\n         this.play()\n         resolve({ audioBlob, audioUrl });\n       });\n \n-      this.mediaRecorder && this.mediaRecorder.stop();\n     });\n+\n   }\n \n   play() {\n     this.audio && this.audio.play();\n"
                },
                {
                    "date": 1681608321545,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,19 +23,17 @@\n \n   stop() {\n     this.mediaRecorder && this.mediaRecorder.stop();\n \n-    new Promise(resolve => {\n-      this.mediaRecorder && this.mediaRecorder.addEventListener(\"stop\", () => {\n-        const audioBlob = new Blob(this.audioChunks);\n-        const audioUrl = URL.createObjectURL(audioBlob);\n-        this.audio = new Audio(audioUrl);\n-        this.play()\n-        resolve({ audioBlob, audioUrl });\n-      });\n-\n+    this.mediaRecorder && this.mediaRecorder.addEventListener(\"stop\", () => {\n+      console.log('stop', stop)\n+      const audioBlob = new Blob(this.audioChunks);\n+      const audioUrl = URL.createObjectURL(audioBlob);\n+      this.audio = new Audio(audioUrl);\n+      this.play()\n     });\n \n+\n   }\n \n   play() {\n     this.audio && this.audio.play();\n"
                },
                {
                    "date": 1681608346684,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,9 +23,9 @@\n \n   stop() {\n     this.mediaRecorder && this.mediaRecorder.stop();\n \n-    this.mediaRecorder && this.mediaRecorder.addEventListener(\"stop\", () => {\n+    this.mediaRecorder!.addEventListener(\"stop\", () => {\n       console.log('stop', stop)\n       const audioBlob = new Blob(this.audioChunks);\n       const audioUrl = URL.createObjectURL(audioBlob);\n       this.audio = new Audio(audioUrl);\n"
                },
                {
                    "date": 1681608385922,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -21,9 +21,9 @@\n     this.mediaRecorder && this.mediaRecorder.start();\n   }\n \n   stop() {\n-    this.mediaRecorder && this.mediaRecorder.stop();\n+   this.mediaRecorder!.stop();\n \n     this.mediaRecorder!.addEventListener(\"stop\", () => {\n       console.log('stop', stop)\n       const audioBlob = new Blob(this.audioChunks);\n"
                },
                {
                    "date": 1681608394030,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -21,12 +21,13 @@\n     this.mediaRecorder && this.mediaRecorder.start();\n   }\n \n   stop() {\n+    console.log('stop record')\n+\n    this.mediaRecorder!.stop();\n \n     this.mediaRecorder!.addEventListener(\"stop\", () => {\n-      console.log('stop', stop)\n       const audioBlob = new Blob(this.audioChunks);\n       const audioUrl = URL.createObjectURL(audioBlob);\n       this.audio = new Audio(audioUrl);\n       this.play()\n"
                },
                {
                    "date": 1681608455621,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,8 +12,9 @@\n     this.stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n     this.mediaRecorder = new MediaRecorder(this.stream);\n \n     this.mediaRecorder.addEventListener(\"dataavailable\", event => {\n+      console.log('event', event)\n       this.audioChunks.push(event.data);\n     });\n   }\n \n@@ -23,9 +24,9 @@\n \n   stop() {\n     console.log('stop record')\n \n-   this.mediaRecorder!.stop();\n+    this.mediaRecorder!.stop();\n \n     this.mediaRecorder!.addEventListener(\"stop\", () => {\n       const audioBlob = new Blob(this.audioChunks);\n       const audioUrl = URL.createObjectURL(audioBlob);\n"
                },
                {
                    "date": 1681608487694,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,9 +12,8 @@\n     this.stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n     this.mediaRecorder = new MediaRecorder(this.stream);\n \n     this.mediaRecorder.addEventListener(\"dataavailable\", event => {\n-      console.log('event', event)\n       this.audioChunks.push(event.data);\n     });\n   }\n \n"
                },
                {
                    "date": 1681611893853,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -40,4 +40,151 @@\n     this.audio && this.audio.play();\n   }\n \n }\n+\n+\n+declare let window: any;\n+\n+let source: any = null;\n+let playTime: number = 0;       // 相对时间，记录暂停位置\n+let playStamp: number = 0;      // 开始或暂停后开始的时间戳(绝对)\n+let context: any = null;\n+let analyser: any = null;\n+\n+let audioData: any = null;\n+// let hasInit: boolean = false;           // 是否已经初始化了\n+let isPaused: boolean = false;\n+let totalTime: number = 0;\n+let endplayFn: any = function() {};\n+\n+/**\n+ * 初始化\n+ */\n+function init(): void {\n+    context = new (window.AudioContext || window.webkitAudioContext)();\n+    analyser = context.createAnalyser();\n+    analyser.fftSize = 2048;                   // 表示存储频域的大小\n+}\n+\n+/**\n+ * play\n+ * @returns {Promise<{}>}\n+ */\n+function playAudio(): Promise<{}> {\n+    isPaused = false;\n+\n+    return context.decodeAudioData(audioData.slice(0), (buffer: any) => {\n+        source = context.createBufferSource();\n+\n+        // 播放结束的事件绑定\n+        source.onended = () => {\n+            if (!isPaused) {  // 暂停的时候也会触发该事件\n+                // 计算音频总时长\n+                totalTime = context.currentTime - playStamp + playTime;\n+                endplayFn();\n+            }\n+\n+        }\n+\n+        // 设置数据\n+        source.buffer = buffer;\n+        // connect到分析器，还是用录音的，因为播放时不能录音的\n+        source.connect(analyser);\n+        analyser.connect(context.destination);\n+        source.start(0, playTime);\n+\n+        // 记录当前的时间戳，以备暂停时使用\n+        playStamp = context.currentTime;\n+    }, function(e: any) {\n+        console.log('error:',e);\n+    });\n+}\n+\n+// 销毁source, 由于 decodeAudioData 产生的source每次停止后就不能使用，所以暂停也意味着销毁，下次需重新启动。\n+function destroySource() {\n+    if (source) {\n+        source.stop();\n+        source = null;\n+    }\n+}\n+\n+export default class Player {\n+    /**\n+     * play record\n+     * @static\n+     * @param {ArrayBuffer} arraybuffer\n+     * @memberof Player\n+     */\n+    static play(arraybuffer: any): Promise<{}> {\n+        if (!context) {\n+            // 第一次播放要初始化\n+            init();\n+        }\n+        this.stopPlay();\n+        // 缓存播放数据\n+        audioData = arraybuffer;\n+        totalTime = 0;\n+\n+        return playAudio();\n+    }\n+\n+    /**\n+     * 暂停播放录音\n+     * @memberof Player\n+     */\n+    static pausePlay(): void {\n+        destroySource();\n+        // 多次暂停需要累加\n+        playTime += context.currentTime - playStamp;\n+        isPaused = true;\n+    }\n+\n+    /**\n+     * 恢复播放录音\n+     * @memberof Player\n+     */\n+    static resumePlay(): Promise<{}> {\n+        return playAudio();\n+    }\n+\n+    /**\n+     * 停止播放\n+     * @memberof Player\n+     */\n+    static stopPlay() {\n+        playTime = 0;\n+        audioData = null;\n+\n+        destroySource();\n+    }\n+\n+    static destroyPlay() {\n+        this.stopPlay();\n+    }\n+\n+    static getAnalyseData() {\n+        let dataArray = new Uint8Array(analyser.frequencyBinCount);\n+        // 将数据拷贝到dataArray中。\n+        analyser.getByteTimeDomainData(dataArray);\n+\n+        return dataArray;\n+    }\n+\n+    /**\n+     * 增加录音播放完成的事件绑定\n+     *\n+     * @static\n+     * @param {*} [fn=function() {}]\n+     * @memberof Player\n+     */\n+    static addPlayEnd(fn: any = function() {}) {\n+        endplayFn = fn;\n+    }\n+\n+    // 获取已经播放的时长\n+    static getPlayTime(): number {\n+        let pTime = isPaused ? playTime : context.currentTime - playStamp + playTime;\n+\n+        return totalTime || pTime;\n+    }\n+}\n"
                },
                {
                    "date": 1681611925344,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -107,9 +107,9 @@\n         source = null;\n     }\n }\n \n-export default class Player {\n+export  class Player {\n     /**\n      * play record\n      * @static\n      * @param {ArrayBuffer} arraybuffer\n"
                },
                {
                    "date": 1681618078796,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,148 @@\n+\n+\n+\n+declare let window: any;\n+\n+let source: any = null;\n+let playTime: number = 0;       // 相对时间，记录暂停位置\n+let playStamp: number = 0;      // 开始或暂停后开始的时间戳(绝对)\n+let context: any = null;\n+let analyser: any = null;\n+\n+let audioData: any = null;\n+// let hasInit: boolean = false;           // 是否已经初始化了\n+let isPaused: boolean = false;\n+let totalTime: number = 0;\n+let endplayFn: any = function() {};\n+\n+/**\n+ * 初始化\n+ */\n+function init(): void {\n+    context = new (window.AudioContext || window.webkitAudioContext)();\n+    analyser = context.createAnalyser();\n+    analyser.fftSize = 2048;                   // 表示存储频域的大小\n+}\n+\n+/**\n+ * play\n+ * @returns {Promise<{}>}\n+ */\n+function playAudio(): Promise<{}> {\n+    isPaused = false;\n+\n+    return context.decodeAudioData(audioData.slice(0), (buffer: any) => {\n+        source = context.createBufferSource();\n+\n+        // 播放结束的事件绑定\n+        source.onended = () => {\n+            if (!isPaused) {  // 暂停的时候也会触发该事件\n+                // 计算音频总时长\n+                totalTime = context.currentTime - playStamp + playTime;\n+                endplayFn();\n+            }\n+\n+        }\n+\n+        // 设置数据\n+        source.buffer = buffer;\n+        // connect到分析器，还是用录音的，因为播放时不能录音的\n+        source.connect(analyser);\n+        analyser.connect(context.destination);\n+        source.start(0, playTime);\n+\n+        // 记录当前的时间戳，以备暂停时使用\n+        playStamp = context.currentTime;\n+    }, function(e: any) {\n+        console.log('error:',e);\n+    });\n+}\n+\n+// 销毁source, 由于 decodeAudioData 产生的source每次停止后就不能使用，所以暂停也意味着销毁，下次需重新启动。\n+function destroySource() {\n+    if (source) {\n+        source.stop();\n+        source = null;\n+    }\n+}\n+\n+export  class Player {\n+    /**\n+     * play record\n+     * @static\n+     * @param {ArrayBuffer} arraybuffer\n+     * @memberof Player\n+     */\n+    static play(arraybuffer: any): Promise<{}> {\n+        if (!context) {\n+            // 第一次播放要初始化\n+            init();\n+        }\n+        this.stopPlay();\n+        // 缓存播放数据\n+        audioData = arraybuffer;\n+        totalTime = 0;\n+\n+        return playAudio();\n+    }\n+\n+    /**\n+     * 暂停播放录音\n+     * @memberof Player\n+     */\n+    static pausePlay(): void {\n+        destroySource();\n+        // 多次暂停需要累加\n+        playTime += context.currentTime - playStamp;\n+        isPaused = true;\n+    }\n+\n+    /**\n+     * 恢复播放录音\n+     * @memberof Player\n+     */\n+    static resumePlay(): Promise<{}> {\n+        return playAudio();\n+    }\n+\n+    /**\n+     * 停止播放\n+     * @memberof Player\n+     */\n+    static stopPlay() {\n+        playTime = 0;\n+        audioData = null;\n+\n+        destroySource();\n+    }\n+\n+    static destroyPlay() {\n+        this.stopPlay();\n+    }\n+\n+    static getAnalyseData() {\n+        let dataArray = new Uint8Array(analyser.frequencyBinCount);\n+        // 将数据拷贝到dataArray中。\n+        analyser.getByteTimeDomainData(dataArray);\n+\n+        return dataArray;\n+    }\n+\n+    /**\n+     * 增加录音播放完成的事件绑定\n+     *\n+     * @static\n+     * @param {*} [fn=function() {}]\n+     * @memberof Player\n+     */\n+    static addPlayEnd(fn: any = function() {}) {\n+        endplayFn = fn;\n+    }\n+\n+    // 获取已经播放的时长\n+    static getPlayTime(): number {\n+        let pTime = isPaused ? playTime : context.currentTime - playStamp + playTime;\n+\n+        return totalTime || pTime;\n+    }\n+}\n"
                }
            ],
            "date": 1681606598334,
            "name": "Commit-0",
            "content": "import Recorder from 'recorder-core'\nimport 'recorder-core/src/engine/mp3'\n\n\n\n\nvar rec: any;\n/**调用open打开录音请求好录音权限**/\nexport const MicrophoneRecord = function (success: () => any) {//一般在显示出录音按钮或相关的录音界面时进行此方法调用，后面用户点击开始录音时就能畅通无阻了\n  rec = Recorder({ //本配置参数请参考下面的文档，有详细介绍\n    type: \"mp3\", sampleRate: 16000, bitRate: 16 //mp3格式，指定采样率hz、比特率kbps，其他参数使用默认配置；注意：是数字的参数必须提供数字，不要用字符串；需要使用的type类型，需提前把格式支持文件加载进来，比如使用wav格式需要提前加载wav.js编码引擎\n    , onProcess: function (buffers: any, powerLevel: any, bufferDuration: any, bufferSampleRate: any, newBufferIdx: any, asyncEnd: any) {\n      //录音实时回调，大约1秒调用12次本回调，buffers为开始到现在的所有录音pcm数据块(16位小端LE)\n      //可实时绘制波形（extensions目录内的waveview.js、wavesurfer.view.js、frequency.histogram.view.js插件功能）\n      //可利用extensions/sonic.js插件实时变速变调，此插件计算量巨大，onProcess需要返回true开启异步模式\n      //可实时上传（发送）数据，配合Recorder.SampleData方法，将buffers中的新数据连续的转换成pcm上传，或使用mock方法将新数据连续的转码成其他格式上传，可以参考文档里面的：Demo片段列表 -> 实时转码并上传-通用版；基于本功能可以做到：实时转发数据、实时保存数据、实时语音识别（ASR）等\n    }\n  });\n\n  //var dialog=createDelayDialog(); 我们可以选择性的弹一个对话框：为了防止移动端浏览器存在第三种情况：用户忽略，并且（或者国产系统UC系）浏览器没有任何回调，此处demo省略了弹窗的代码\n  rec.open(function () {//打开麦克风授权获得相关资源\n    //dialog&&dialog.Cancel(); 如果开启了弹框，此处需要取消\n    //rec.start() 此处可以立即开始录音，但不建议这样编写，因为open是一个延迟漫长的操作，通过两次用户操作来分别调用open和start是推荐的最佳流程\n\n    success && success();\n  }, function (msg: string, isUserNotAllow: any) {//用户拒绝未授权或不支持\n    //dialog&&dialog.Cancel(); 如果开启了弹框，此处需要取消\n    console.log((isUserNotAllow ? \"UserNotAllow，\" : \"\") + \"无法录音:\" + msg);\n  });\n};\n\n/**开始录音**/\nfunction recStart() {//打开了录音后才能进行start、stop调用\n  rec.start();\n};\n\n/**结束录音**/\nfunction recStop() {\n  rec.stop(function (blob: Blob | MediaSource, duration: string) {\n    console.log(blob, (window.URL || webkitURL).createObjectURL(blob), \"时长:\" + duration + \"ms\");\n    rec.close();//释放录音资源，当然可以不释放，后面可以连续调用start；但不释放时系统或浏览器会一直提示在录音，最佳操作是录完就close掉\n    rec = null;\n\n    //已经拿到blob文件对象想干嘛就干嘛：立即播放、上传\n\n    /*** 【立即播放例子】 ***/\n    var audio = document.createElement(\"audio\");\n    audio.controls = true;\n    document.body.appendChild(audio);\n    //简单利用URL生成播放地址，注意不用了时需要revokeObjectURL，否则霸占内存\n    audio.src = (window.URL || webkitURL).createObjectURL(blob);\n    audio.play();\n  }, function (msg: string) {\n    console.log(\"录音失败:\" + msg);\n    rec.close();//可以通过stop方法的第3个参数来自动调用close\n    rec = null;\n  });\n};\n\n\n//我们可以选择性的弹一个对话框：为了防止移动端浏览器存在第三种情况：用户忽略，并且（或者国产系统UC系）浏览器没有任何回调\n/*伪代码：\nfunction createDelayDialog(){\n    if(Is Mobile){//只针对移动端\n        return new Alert Dialog Component\n            .Message(\"录音功能需要麦克风权限，请允许；如果未看到任何请求，请点击忽略~\")\n            .Button(\"忽略\")\n            .OnClick(function(){//明确是用户点击的按钮，此时代表浏览器没有发起任何权限请求\n                //此处执行fail逻辑\n                console.log(\"无法录音：权限请求被忽略\");\n            })\n            .OnCancel(NOOP)//自动取消的对话框不需要任何处理\n            .Delay(8000); //延迟8秒显示，这么久还没有操作基本可以判定浏览器有毛病\n    };\n};\n*/\n\n\n//这里假设立即运行，只录3秒，录完后立即播放，本段代码copy到控制台内可直接运行\n// recOpen(function () {\n//   recStart();\n//   setTimeout(recStop, 3000);\n// });"
        }
    ]
}