{
    "sourceFile": "src/models/ChatMessage.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 2,
            "patches": [
                {
                    "date": 1681897804693,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1681973622216,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,52 +1,52 @@\n-import encoder from \"@nem035/gpt-3-encoder\";\n+import encoder from '@nem035/gpt-3-encoder'\n \n-export const countTokens = (text: string) => encoder.encode(text).length;\n+export const countTokens = (text: string) => encoder.encode(text).length\n \n export interface Message {\n-  id: string;\n-  content: string;\n-  role: \"user\" | \"assistant\" | \"system\";\n-  loading?: boolean;\n+  id: string\n+  content: string\n+  role: 'user' | 'assistant' | 'system'\n+  loading?: boolean\n }\n \n function estimateTokens(content: string): number {\n-  const words = content.trim().split(/\\s+/).length;\n-  return Math.ceil(words * (100 / 75));\n+  const words = content.trim().split(/\\s+/).length\n+  return Math.ceil(words * (100 / 75))\n }\n \n // Truncate messages\n export function truncateMessages(\n   messages: Message[],\n   modelMaxTokens: number,\n-  userMaxTokens: number\n+  userMaxTokens: number,\n ): Message[] {\n-  if (messages.length <= 1) return messages;\n+  if (messages.length <= 1) return messages\n \n   if (!userMaxTokens) {\n-    userMaxTokens = 1024;\n+    userMaxTokens = 1024\n   }\n-  const targetTokens = modelMaxTokens - userMaxTokens;\n+  const targetTokens = modelMaxTokens - userMaxTokens\n \n-  let accumulatedTokens = 0;\n-  const ret = [];\n-  let startIdx = 0;\n+  let accumulatedTokens = 0\n+  const ret = []\n+  let startIdx = 0\n \n-  if (messages[0].role === \"system\") {\n-    accumulatedTokens = estimateTokens(messages[0].content);\n-    ret.push(messages[0]);\n-    startIdx = 1;\n+  if (messages[0].role === 'system') {\n+    accumulatedTokens = estimateTokens(messages[0].content)\n+    ret.push(messages[0])\n+    startIdx = 1\n   }\n \n   // Try to truncate messages as is\n   for (let i = messages.length - 1; i >= startIdx; i--) {\n-    const message = messages[i];\n-    const tokens = estimateTokens(message.content);\n+    const message = messages[i]\n+    const tokens = estimateTokens(message.content)\n     if (accumulatedTokens + tokens > targetTokens) {\n-      break;\n+      break\n     }\n-    accumulatedTokens += tokens;\n+    accumulatedTokens += tokens\n     // Insert at position 1\n-    ret.splice(1, 0, message);\n+    ret.splice(1, 0, message)\n   }\n-  return ret;\n+  return ret\n }\n"
                },
                {
                    "date": 1682010121445,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,4 +1,12 @@\n+/*\n+ * @Author: Allen OYang\n+ * @Email:  allenwill211@gmail.com\n+ * @Date: 2023-04-17 22:34:23\n+ * @LastEditTime: 2023-04-20 14:53:42\n+ * @LastEditors: Allen OYang allenwill211@gmail.com\n+ * @FilePath: /speak-gpt/src/models/ChatMessage.ts\n+ */\n import encoder from '@nem035/gpt-3-encoder'\n \n export const countTokens = (text: string) => encoder.encode(text).length\n \n@@ -47,6 +55,7 @@\n     accumulatedTokens += tokens\n     // Insert at position 1\n     ret.splice(1, 0, message)\n   }\n+  console.log('ret', ret)\n   return ret\n }\n"
                }
            ],
            "date": 1681897804693,
            "name": "Commit-0",
            "content": "import encoder from \"@nem035/gpt-3-encoder\";\n\nexport const countTokens = (text: string) => encoder.encode(text).length;\n\nexport interface Message {\n  id: string;\n  content: string;\n  role: \"user\" | \"assistant\" | \"system\";\n  loading?: boolean;\n}\n\nfunction estimateTokens(content: string): number {\n  const words = content.trim().split(/\\s+/).length;\n  return Math.ceil(words * (100 / 75));\n}\n\n// Truncate messages\nexport function truncateMessages(\n  messages: Message[],\n  modelMaxTokens: number,\n  userMaxTokens: number\n): Message[] {\n  if (messages.length <= 1) return messages;\n\n  if (!userMaxTokens) {\n    userMaxTokens = 1024;\n  }\n  const targetTokens = modelMaxTokens - userMaxTokens;\n\n  let accumulatedTokens = 0;\n  const ret = [];\n  let startIdx = 0;\n\n  if (messages[0].role === \"system\") {\n    accumulatedTokens = estimateTokens(messages[0].content);\n    ret.push(messages[0]);\n    startIdx = 1;\n  }\n\n  // Try to truncate messages as is\n  for (let i = messages.length - 1; i >= startIdx; i--) {\n    const message = messages[i];\n    const tokens = estimateTokens(message.content);\n    if (accumulatedTokens + tokens > targetTokens) {\n      break;\n    }\n    accumulatedTokens += tokens;\n    // Insert at position 1\n    ret.splice(1, 0, message);\n  }\n  return ret;\n}\n"
        }
    ]
}