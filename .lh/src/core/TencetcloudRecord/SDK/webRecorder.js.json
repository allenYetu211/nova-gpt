{
    "sourceFile": "src/core/TencetcloudRecord/SDK/webRecorder.js",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1681701992275,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1681704697884,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -32,9 +32,8 @@\n }\n \n registerProcessor('my-processor', MyProcessor);\n `;\n-const audioWorkletBlobURL = window.URL.createObjectURL(new Blob([audioWorkletCode], { type: 'text/javascript' }));\n \n function to16BitPCM(input) {\n   const dataLength = input.length * (16 / 8);\n   const dataBuffer = new ArrayBuffer(dataLength);\n@@ -135,8 +134,10 @@\n     const getAudioSuccess = (stream) => {\n       this.stream = stream;\n       const mediaStreamSource = this.audioContext.createMediaStreamSource(this.stream); // 将声音对象输入这个对象\n       if (this.audioContext.audioWorklet) {\n+        const audioWorkletBlobURL = window.URL.createObjectURL(new Blob([audioWorkletCode], { type: 'text/javascript' }));\n+\n         this.audioContext.audioWorklet.addModule(audioWorkletBlobURL).then(() => {\n           const myNode = new AudioWorkletNode(this.audioContext, 'my-processor', { numberOfInputs: 1, numberOfOutputs: 1, channelCount: 1 });\n           myNode.port.onmessage = (event) => {\n             this.OnReceivedData(event.data.audioData);\n"
                }
            ],
            "date": 1681701992275,
            "name": "Commit-0",
            "content": "const audioWorkletCode = `\nclass MyProcessor extends AudioWorkletProcessor {\n  constructor(options) {\n    super(options);\n    this.audioData = [];\n    this.nextUpdateFrame = 40;\n  }\n\n  get intervalInFrames() {\n    return 200 / 1000 * sampleRate;\n  }\n\n  process(inputs) {\n    // 去处理音频数据\n    // eslint-disable-next-line no-undef\n    if (inputs[0][0]) {\n      const output = ${to16kHz}(inputs[0][0], sampleRate);\n      const audioData = ${to16BitPCM}(output);\n      const data = [...new Int8Array(audioData.buffer)];\n      this.audioData = this.audioData.concat(data);\n      this.nextUpdateFrame -= inputs[0][0].length;\n      if (this.nextUpdateFrame < 0) {\n        this.nextUpdateFrame += this.intervalInFrames;\n        this.port.postMessage({\n          audioData: new Int8Array(this.audioData)\n        });\n        this.audioData = [];\n      }\n        return true;\n      }\n  }\n}\n\nregisterProcessor('my-processor', MyProcessor);\n`;\nconst audioWorkletBlobURL = window.URL.createObjectURL(new Blob([audioWorkletCode], { type: 'text/javascript' }));\n\nfunction to16BitPCM(input) {\n  const dataLength = input.length * (16 / 8);\n  const dataBuffer = new ArrayBuffer(dataLength);\n  const dataView = new DataView(dataBuffer);\n  let offset = 0;\n  for (let i = 0; i < input.length; i++, offset += 2) {\n    const s = Math.max(-1, Math.min(1, input[i]));\n    dataView.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);\n  }\n  return dataView;\n}\nfunction to16kHz(audioData, sampleRate= 44100) {\n  const data = new Float32Array(audioData);\n  const fitCount = Math.round(data.length * (16000 / sampleRate));\n  const newData = new Float32Array(fitCount);\n  const springFactor = (data.length - 1) / (fitCount - 1);\n  newData[0] = data[0];\n  for (let i = 1; i < fitCount - 1; i++) {\n    const tmp = i * springFactor;\n    const before = Math.floor(tmp).toFixed();\n    const after = Math.ceil(tmp).toFixed();\n    const atPoint = tmp - before;\n    newData[i] = data[before] + (data[after] - data[before]) * atPoint;\n  }\n  newData[fitCount - 1] = data[data.length - 1];\n  return newData;\n}\n\n/**\n * 录音类\n */\nexport default class WebRecorder {\n  constructor() {\n    this.audioData = [];\n    this.stream = null;\n    this.audioContext = null;\n    if (!WebRecorder.instance) {\n      WebRecorder.instance = this;\n    }\n  }\n  start() {\n    if (this.audioContext) {\n      this.OnError('录音已开启');\n      return;\n    }\n    navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia\n      || navigator.mozGetUserMedia || navigator.msGetUserMedia;\n\n    try {\n      this.audioContext = new (window.AudioContext || window.webkitAudioContext)();\n      this.audioContext.resume();\n      if (!this.audioContext) {\n        this.OnError('浏览器不支持webAudioApi相关接口');\n        return;\n      }\n    } catch (e) {\n      if (!this.audioContext) {\n        this.OnError('浏览器不支持webAudioApi相关接口');\n        return;\n      }\n    }\n\n    // 获取用户的麦克风\n    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n      navigator.mediaDevices\n        .getUserMedia({\n          audio: true,\n          video: false,\n        })\n        .then(stream => {\n            getAudioSuccess(stream);\n        })\n        .catch(e => {\n          getAudioFail(e);\n        });\n    } else if (navigator.getUserMedia) {\n      navigator.getUserMedia(\n        {\n          audio: true,\n          video: false,\n        },\n        stream => {\n          getAudioSuccess(stream);\n        },\n        function(e) {\n          getAudioFail(e);\n        }\n      );\n    } else {\n      if (navigator.userAgent.toLowerCase().match(/chrome/) && location.origin.indexOf('https://') < 0) {\n        this.OnError('chrome下获取浏览器录音功能，因为安全性问题，需要在localhost或127.0.0.1或https下才能获取权限');\n      } else {\n        this.OnError('无法获取浏览器录音功能，请升级浏览器或使用chrome');\n      }\n      this.audioContext && this.audioContext.close();\n      return;\n    }\n    const getAudioSuccess = (stream) => {\n      this.stream = stream;\n      const mediaStreamSource = this.audioContext.createMediaStreamSource(this.stream); // 将声音对象输入这个对象\n      if (this.audioContext.audioWorklet) {\n        this.audioContext.audioWorklet.addModule(audioWorkletBlobURL).then(() => {\n          const myNode = new AudioWorkletNode(this.audioContext, 'my-processor', { numberOfInputs: 1, numberOfOutputs: 1, channelCount: 1 });\n          myNode.port.onmessage = (event) => {\n            this.OnReceivedData(event.data.audioData);\n          };\n          mediaStreamSource.connect(myNode).connect(this.audioContext.destination);\n        })\n          .catch(console.error);\n      } else {\n        // 创建一个音频分析对象，采样的缓冲区大小为0（自动适配），输入和输出都是单声道\n        const scriptProcessor = this.audioContext.createScriptProcessor(0, 1, 1);\n        scriptProcessor.onaudioprocess = (e) => {\n          // 去处理音频数据\n          const inputData = e.inputBuffer.getChannelData(0);\n          const output = to16kHz(inputData, this.audioContext.sampleRate);\n          const audioData = to16BitPCM(output);\n          this.audioData.push(...new Int8Array(audioData.buffer));\n          if (this.audioData.length > 6400) {\n            const audioDataArray = new Int8Array(this.audioData);\n            this.OnReceivedData(audioDataArray);\n            this.audioData = [];\n          }\n        };\n        // 连接\n        mediaStreamSource.connect(scriptProcessor);\n        scriptProcessor.connect(this.audioContext.destination);\n      }\n    };\n    const getAudioFail = (err) => {\n      this.OnError(err);\n      this.stop();\n    };\n  }\n  stop() {\n    if (!(/Safari/.test(navigator.userAgent) && !/Chrome/.test(navigator.userAgent))){\n      this.audioContext && this.audioContext.suspend();\n    }\n    this.audioContext && this.audioContext.suspend();\n    // 关闭通道\n    if (this.stream) {\n      this.stream.getTracks().map((val) => {\n        val.stop();\n      });\n      this.stream = null;\n    }\n  }\n  OnReceivedData(data) { // 获取音频数据\n\n  }\n  OnError(res) {\n\n  }\n}"
        }
    ]
}